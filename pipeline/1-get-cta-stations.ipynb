{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import linemerge, unary_union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data.constants import (WORLD_CRS, \n",
    "    L_STATIONS_TABLE, L_LINES_TABLE, BUS_ROUTES_TABLE, BUS_STOPS_TABLE)\n",
    "from data.cta import CTAClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations_out = \"../data/raw/train_stations.geojson\"\n",
    "train_lines_out = \"../data/raw/train_lines.geojson\"\n",
    "bus_routes_file_out = \"../data/raw/bus_routes.geojson\"\n",
    "bus_stops_file_out = \"../data/raw/bus_stops.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CTAClient(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline in\n",
    "\n",
    "(none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations = client.soda_get_all(L_STATIONS_TABLE, select=\"stop_id, direction_id, stop_name, station_name, map_id, location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_stations['location'].apply(shape) # is not working!\n",
    "train_stations['latitude'] = train_stations['location'].apply(lambda x: x['latitude'])\n",
    "train_stations['longitude'] = train_stations['location'].apply(lambda x: x['longitude'])\n",
    "train_stations['geometry'] = gpd.points_from_xy(train_stations['longitude'], train_stations['latitude'])\n",
    "train_stations = train_stations.drop(columns=['location', 'latitude', 'longitude'])\n",
    "train_stations = gpd.GeoDataFrame(train_stations, geometry='geometry',crs=WORLD_CRS)\n",
    "# nb: Each train station is represented as two \"stops\" per station: one in each direction.\n",
    "#     For our purposes, since we don't model the direction of travel, we will drop the redundant \"stop\".\n",
    "train_stations = train_stations.drop_duplicates(['station_name','map_id','geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to get lines in two parts becuase the datasets are hard to merge.\n",
    "\n",
    "1. First, we just take the line identifiers, which do exist in the stations table.\n",
    "2. Next we get the actual line segments table, which is better for geo mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is wide, so we need to consolidate and narrow it.\n",
    "lines = ['red','blue','g','brn','p','pexp','y','pnk','o']\n",
    "line_names = ['red','blue','green','brown','purple','purpleexp','yellow','pink','orange']\n",
    "station_ids = ['station_name', 'map_id']\n",
    "\n",
    "station_to_line = client.soda_get_all(L_STATIONS_TABLE, select=f\"{','.join(station_ids)}, {','.join(lines)}\")\n",
    "station_to_line = station_to_line.rename(columns=dict(zip(lines, line_names)))\n",
    "station_to_line['purple'] = station_to_line['purple'] | station_to_line['purpleexp']\n",
    "station_to_line = station_to_line.drop(columns=['purpleexp'])\n",
    "station_to_line = station_to_line.melt(id_vars=station_ids, var_name='line', value_name='is_line')\n",
    "station_to_line = station_to_line.query('is_line').drop(columns='is_line')\n",
    "station_to_line = station_to_line.groupby(station_ids, as_index=False)['line'].agg(lambda x: ','.join(set(x)))\n",
    "\n",
    "train_stations = train_stations.merge(station_to_line, how='left')\n",
    "assert train_stations['line'].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the legit lines gdf but it doesn't have neat identifiers to relate to the stations.\n",
    "train_lines = gpd.read_file(L_LINES_TABLE)\n",
    "train_lines['single_line'] = train_lines['legend'].map({'BR':'brown','YL':'yellow','GR':'green',\n",
    "                                        'OR':'orange','RD':'red','BL':'blue',\n",
    "                                        'PK':'pink','PR':'purple'})\n",
    "train_lines['multi_lines'] = train_lines['lines'].str.split(', ')\n",
    "train_lines = train_lines.explode('multi_lines')\n",
    "train_lines['multi_lines'] = train_lines['multi_lines'].str.lower().str.replace('(express)','').str.replace('(exp)','').str.strip()\n",
    "train_lines['line'] = np.where(train_lines['single_line'].notna(), train_lines['single_line'], train_lines['multi_lines'])\n",
    "train_lines = train_lines.filter(['geometry','line']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table is station-to-station segments. Need to merge into one row per line.\n",
    "\n",
    "def merge_lines(x: gpd.GeoSeries):\n",
    "    merged = unary_union(x)\n",
    "    return linemerge(merged) if merged.is_simple else merged\n",
    "\n",
    "crs = train_lines.crs\n",
    "train_lines = train_lines.groupby('line', as_index=False)['geometry'].agg(merge_lines)\n",
    "train_lines = train_lines.set_crs(crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_routes =  client.soda_get_all(BUS_ROUTES_TABLE, select=\"the_geom, route, name\")\n",
    "# HACK: This one route is mysteriously present online but not returned by API??\n",
    "roosevelt_route = gpd.read_file(\"../data/raw/roosevelt_route.geojson\")\n",
    "bus_routes['geometry'] = bus_routes['the_geom'].apply(shape)\n",
    "bus_routes = bus_routes.drop(columns='the_geom')\n",
    "bus_routes = pd.concat([bus_routes, roosevelt_route], ignore_index=True)\n",
    "bus_routes = gpd.GeoDataFrame(bus_routes, geometry='geometry',crs=WORLD_CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops = gpd.read_file(BUS_STOPS_TABLE, columns=['STREET','CROSS_ST','CITY','PUBLIC_NAM','ROUTESSTPG','geometry'])\n",
    "bus_stops = bus_stops.rename(columns={'PUBLIC_NAM':'PUBLIC_NAME'})\n",
    "# STREET CROSS_ST CITY is the composite non-unique PK for this table\n",
    "#   - it is not unique due to large multi-bay transit centers that are conceptually co-located\n",
    "# PUBLIC_NAM is human-readable but it is ambiguous concerning:\n",
    "#   - repeated street names in chicago vs evanston\n",
    "#   - repeated street/transit intersections across chicago e.g. Western"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 4 rows\n"
     ]
    }
   ],
   "source": [
    "# Drop bus stops without route labels. Won't be able to get ridership for these.\n",
    "print(\"Dropping {} rows\".format(bus_stops['ROUTESSTPG'].isna().sum()))\n",
    "bus_stops = bus_stops.dropna(subset='ROUTESSTPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing 1 rows\n"
     ]
    }
   ],
   "source": [
    "# Impute city for unknown cities\n",
    "print(\"Imputing {} rows\".format(bus_stops['CITY'].isna().sum()))\n",
    "bus_stops['CITY'] = bus_stops['CITY'].fillna('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops['ROUTESSTPG'] = bus_stops['ROUTESSTPG'].str.split(',')\n",
    "bus_stops = bus_stops.explode('ROUTESSTPG').rename(columns={'ROUTESSTPG':'route'})\n",
    "# nb: Compared to train stations, bus stop pairs on opposite sides of the street\n",
    "#     aren't AS CLEANLY paired in the dataset. Though we could spatially join them\n",
    "#     as 1-nearest-neighbor if we really wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metra Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metra does not provide machine-readable ridership reports. They have bar graphs of weekly total ridership and monthly ridership by line.\n",
    "\n",
    "https://metra.com/ridership-reports\n",
    "\n",
    "TODO!\n",
    "\n",
    "But actually the Regional Transit Authority does provide machine-readable monthly ridership by line.\n",
    "\n",
    "https://rtams.org/media/datasets/metra-ridership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations.to_file(train_stations_out, index=False)\n",
    "train_lines.to_file(train_lines_out, index=False)\n",
    "bus_routes.to_file(bus_routes_file_out, index=False)\n",
    "bus_stops.to_file(bus_stops_file_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
