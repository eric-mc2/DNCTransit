{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**\n",
    "\n",
    "*This notebook introduces substantive modeling choices e.g.*\n",
    "- data aggregation, \n",
    "- dropping missing data, \n",
    "- and coding more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "\n",
    "from data.constants import DNC_START, DNC_END, LOCAL_CRS, WORLD_CRS\n",
    "from data.datemath import from_ymd, date_aggs, to_yw\n",
    "from power import power_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel_in = \"../data/interim/point_panel.parquet\"\n",
    "line_panel_in = \"../data/interim/line_panel.parquet\"\n",
    "tract_panel_in = \"../data/interim/tract_panel.parquet\"\n",
    "comm_panel_in = \"../data/interim/comm_panel.parquet\"\n",
    "tracts_in = \"../data/interim/tracts.geoparquet\"\n",
    "\n",
    "point_panel_out = \"../data/final/point_panel.parquet\"\n",
    "line_panel_out = \"../data/final/line_panel.parquet\"\n",
    "tract_panel_out = \"../data/final/tract_panel.parquet\"\n",
    "comm_panel_out = \"../data/final/comm_panel.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel = gpd.read_parquet(point_panel_in)\n",
    "line_panel = gpd.read_parquet(line_panel_in)\n",
    "tract_panel = gpd.read_parquet(tract_panel_in)\n",
    "comm_panel = gpd.read_parquet(comm_panel_in)\n",
    "tracts = gpd.read_parquet(tracts_in)['geoid10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel = point_panel.pipe(date_aggs, 'date')\n",
    "line_panel = line_panel.pipe(date_aggs, 'date')\n",
    "tract_panel = tract_panel.pipe(date_aggs, 'date')\n",
    "comm_panel = comm_panel.pipe(date_aggs, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substantive!\n",
    "# There aren't enough data points within 400m or even 800m.\n",
    "# In panel.ipynb we show that UC and MP have higher ridership than other\n",
    "# places, and furthermore that the signal is stronger closer to UC and MP\n",
    "# and reverts to the mean as the buffer size grows.\n",
    "# Thus, using the largest buffer size attenuates and possibly confounds our\n",
    "# signal with irrelevant rides, but is necessary to achieve a minimal sample\n",
    "# of treated units.\n",
    "\n",
    "def label_ucmp(df):\n",
    "    df['UCMP'] = np.where((df['uc_1600'] > 0) | (df['mp_1600'] > 0), 1,0)\n",
    "    return df.drop(columns=df.filter(regex='uc_|mp_').columns)\n",
    "\n",
    "point_panel = point_panel.pipe(label_ucmp)\n",
    "line_panel = line_panel.pipe(label_ucmp)\n",
    "tract_panel = tract_panel.pipe(label_ucmp)\n",
    "comm_panel = comm_panel.pipe(label_ucmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df, fills: dict):\n",
    "    return df.assign(**{col: df[col].fillna(val) for col, val in fills.items()})\n",
    "\n",
    "# Assert that null features are due to non-chicago tracts. \n",
    "# Let's impute correct values instead of dropping tracts outside of chicago (ie ubers and bike stations)\n",
    "assert all(tract_panel['UCMP'].notna() | ~tract_panel['id'].isin(tracts))\n",
    "assert all(tract_panel['airport'].notna() | ~tract_panel['id'].isin(tracts))\n",
    "assert all(point_panel[['UCMP','airport']].notna().all(axis=1) |\n",
    "         ((point_panel['transit']=='uber') & point_panel['tract'].notna()))\n",
    "\n",
    "point_panel = point_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})\n",
    "line_panel = line_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})\n",
    "tract_panel = tract_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})\n",
    "comm_panel = comm_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_latlong(df):\n",
    "    # Let's standardize lat/long because they are measured in millions of feet\n",
    "    # So doing so helps keep the relative scale of X vs Y in check. \n",
    "    scale = lambda x: (x - x.mean()) / x.std()\n",
    "    df['lat'] = scale(df.geometry.to_crs(LOCAL_CRS).centroid.to_crs(WORLD_CRS).y)\n",
    "    df['long'] = scale(df.geometry.to_crs(LOCAL_CRS).centroid.to_crs(WORLD_CRS).x)\n",
    "    return df\n",
    "\n",
    "point_panel = point_panel.pipe(label_latlong)\n",
    "line_panel = line_panel.pipe(label_latlong)\n",
    "tract_panel = tract_panel.pipe(label_latlong)\n",
    "comm_panel = comm_panel.pipe(label_latlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(df, col):\n",
    "    return df.assign(**{col: df[col]*1.0})\n",
    "\n",
    "point_panel = point_panel.pipe(binarize, 'DNC')\n",
    "line_panel = line_panel.pipe(binarize, 'DNC')\n",
    "tract_panel = tract_panel.pipe(binarize, 'DNC')\n",
    "comm_panel = comm_panel.pipe(binarize, 'DNC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of Bounds Bike Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 7991 (4%) point rows\n",
      "Dropping 240 (0%) line rows\n",
      "Dropping 3521 (1%) tract rows\n",
      "Dropping 0 (0%) comm rows\n"
     ]
    }
   ],
   "source": [
    "# XXX:\n",
    "# Dropping all nan columns FOR NOW because I don't feel like dealing with it.\n",
    "# We can probably fix it all by getting all cook county census tracts instead of just chicago.\n",
    "\n",
    "print(\"Dropping {} ({:.0%}) point rows\".format(point_panel.isna().any(axis=1).sum(),point_panel.isna().any(axis=1).mean()))\n",
    "print(\"Dropping {} ({:.0%}) line rows\".format(line_panel.isna().any(axis=1).sum(),line_panel.isna().any(axis=1).mean()))\n",
    "print(\"Dropping {} ({:.0%}) tract rows\".format(tract_panel.isna().any(axis=1).sum(),tract_panel.isna().any(axis=1).mean()))\n",
    "print(\"Dropping {} ({:.0%}) comm rows\".format(comm_panel.isna().any(axis=1).sum(),comm_panel.isna().any(axis=1).mean()))\n",
    "point_panel = point_panel.dropna()\n",
    "line_panel = line_panel.dropna()\n",
    "tract_panel = tract_panel.dropna()\n",
    "comm_panel = comm_panel.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Substantive!! \n",
    "#      Taking all weeks in June, July, August\n",
    "MODEL_PRE_WEEKS = 11\n",
    "MODEL_POST_WEEKS = 1\n",
    "\n",
    "model_start_yearweek = to_yw(from_ymd(DNC_START) - timedelta(weeks=MODEL_PRE_WEEKS))\n",
    "model_end_yearweek = to_yw(from_ymd(DNC_END) + timedelta(weeks=MODEL_POST_WEEKS))\n",
    "\n",
    "point_panel = point_panel[point_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]\n",
    "line_panel = line_panel[line_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]\n",
    "tract_panel = tract_panel[tract_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]\n",
    "comm_panel = comm_panel[comm_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_agg(df):\n",
    "    unit_aggs = {k: 'first' for k in ['UCMP','airport','lat','long']}\n",
    "    time_aggs = {'rides':'sum','DNC':'max', 'is_weekend': 'max'}  \n",
    "    # weekend is constant for weekly model but we just won't include it in the model spec\n",
    "    df_weekly = df.groupby(['year-week','id','transit'], as_index=False).agg(unit_aggs | time_aggs)\n",
    "    df_daily = df.groupby(['date','id','transit'], as_index=False).agg(unit_aggs | time_aggs)\n",
    "    return df_weekly, df_daily\n",
    "\n",
    "point_panel_weekly, point_panel_daily = model_agg(point_panel)\n",
    "line_panel_weekly, line_panel_daily = model_agg(line_panel)\n",
    "tract_panel_weekly, tract_panel_daily = model_agg(tract_panel)\n",
    "comm_panel_weekly, comm_panel_daily = model_agg(comm_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose and Justify Agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly: obviously stupid. attenuates treatment too much.\n",
    "\n",
    "Weekly: we have 4/7 days of the week in the DNC. and no weekend days actually.\n",
    "so we attenuate our signal by 3/7. \n",
    "\n",
    "Daily: we have more trouble modeling dotw variation. (maybe not an issue after eliminating weekends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with non-treatment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_r2(full, reduced, full_name, reduced_name):\n",
    "    better = max(full.rsquared, reduced.rsquared)\n",
    "    worse = min(full.rsquared, reduced.rsquared)\n",
    "    partial = (better - worse) / (1 - worse)  # Proportion of unexplained variance explained by better model.\n",
    "    better_name = full_name if full.rsquared > reduced.rsquared else reduced_name\n",
    "    print(\"better model = {}, R2 = {:.3f}, partial R2 = {:.3f}\".format(better_name, better, partial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better model = daily, R2 = 0.771, partial R2 = 0.072\n"
     ]
    }
   ],
   "source": [
    "# Compute the partial R2 of weekly vs daily. Only include non-treatment regressors.\n",
    "formula = \"np.log1p(rides) ~ transit + (lat + long)**2 + I(lat**2) + I(long**2)\"\n",
    "full = sm.OLS.from_formula(formula, point_panel_daily).fit()\n",
    "reduced = sm.OLS.from_formula(formula, point_panel_weekly).fit()\n",
    "partial_r2(full, reduced, \"daily\", \"weekly\")\n",
    "# The weekly model actually has a slightly higher R2, \n",
    "# meaning we're not great at explaining DOTW variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily</th>\n",
       "      <th>weekly</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.440143</td>\n",
       "      <td>4.201957</td>\n",
       "      <td>1.221448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.025104</td>\n",
       "      <td>1.324865</td>\n",
       "      <td>1.292419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mde</th>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>2.928939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_size</th>\n",
       "      <td>1.747618</td>\n",
       "      <td>3.232726</td>\n",
       "      <td>1.84979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_achieved</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_stat</th>\n",
       "      <td>495.19644</td>\n",
       "      <td>312.744557</td>\n",
       "      <td>0.631557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_detectable</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    daily      weekly     ratio\n",
       "mean             3.440143    4.201957  1.221448\n",
       "std              1.025104    1.324865  1.292419\n",
       "mde              0.009887    0.028959  2.928939\n",
       "effect_size      1.747618    3.232726   1.84979\n",
       "power_achieved        1.0         1.0       1.0\n",
       "t_stat          495.19644  312.744557  0.631557\n",
       "is_detectable        True        True       1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power analysis:\n",
    "DNC_ATTEND = 5e4\n",
    "effect_sum = 4 * 2 * DNC_ATTEND  # days in event * rides per day * attendees\n",
    "\n",
    "pd.concat([power_reg(full, np.log1p(effect_sum/len(point_panel_daily))).rename('daily'),\n",
    "           power_reg(reduced, np.log1p(effect_sum/len(point_panel_weekly))).rename('weekly')],axis=1) \\\n",
    "        .assign(ratio=lambda x: x['weekly']/x['daily'])\n",
    "# The daily model has smaller residual variance but identical power achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with treatment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better model = daily, R2 = 0.771, partial R2 = 0.071\n"
     ]
    }
   ],
   "source": [
    "# Compute the partial R2 of weekly vs daily. \n",
    "formula = \"np.log1p(rides) ~ DNC * transit + (lat + long)**2 + I(lat**2) + I(long**2)\"\n",
    "full = sm.OLS.from_formula(formula, point_panel_daily).fit()\n",
    "reduced = sm.OLS.from_formula(formula, point_panel_weekly).fit()\n",
    "partial_r2(full, reduced, \"daily\", \"weekly\")\n",
    "# The weekly model actually has a slightly higher R2, \n",
    "# meaning we're not great at explaining DOTW variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily</th>\n",
       "      <th>weekly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.042378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mde</th>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_size</th>\n",
       "      <td>1.747618</td>\n",
       "      <td>3.232726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_achieved</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_stat</th>\n",
       "      <td>27717.774516</td>\n",
       "      <td>9777.326135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_detectable</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       daily       weekly\n",
       "mean                     0.0          0.0\n",
       "std                 0.018314     0.042378\n",
       "mde                 0.000177     0.000926\n",
       "effect_size         1.747618     3.232726\n",
       "power_achieved           1.0          1.0\n",
       "t_stat          27717.774516  9777.326135\n",
       "is_detectable           True         True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([power_reg(full, np.log1p(effect_sum/len(point_panel_daily)), \"DNC\").rename('daily'),\n",
    "           power_reg(reduced, np.log1p(effect_sum/len(point_panel_weekly)), \"DNC\").rename('weekly')],axis=1) \n",
    "# The standard errors are smaller on the daily model but achieved effect size is net the same,\n",
    "# probably because we didn't change the effect delta but scaled down the nobs and effect size\n",
    "# by the same amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we'll keep the daily observations because it gives us more flexibility to \n",
    "switch to alternative treatment specifications (buffer or event study) later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel_daily.to_parquet(point_panel_out, index=False)\n",
    "line_panel_daily.to_parquet(line_panel_out, index=False)\n",
    "tract_panel_daily.to_parquet(tract_panel_out, index=False)\n",
    "comm_panel_daily.to_parquet(comm_panel_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
