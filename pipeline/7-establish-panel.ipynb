{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**\n",
    "\n",
    "*This notebook introduces substantive modeling choices e.g.*\n",
    "- data aggregation, \n",
    "- dropping missing data, \n",
    "- and coding more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "\n",
    "from data.constants import DNC_START, DNC_END, LOCAL_CRS, WORLD_CRS\n",
    "from data.datemath import from_ymd, date_aggs, to_yw\n",
    "from power import power_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel_in = \"../data/interim/point_panel.parquet\"\n",
    "line_panel_in = \"../data/interim/line_panel.parquet\"\n",
    "tract_panel_in = \"../data/interim/tract_panel.parquet\"\n",
    "comm_panel_in = \"../data/interim/comm_panel.parquet\"\n",
    "tracts_in = \"../data/interim/tracts.geoparquet\"\n",
    "attend_in = \"../data/interim/sports.csv\"\n",
    "\n",
    "point_panel_out = \"../data/final/point_panel.parquet\"\n",
    "line_panel_out = \"../data/final/line_panel.parquet\"\n",
    "tract_panel_out = \"../data/final/tract_panel.parquet\"\n",
    "comm_panel_out = \"../data/final/comm_panel.parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel = gpd.read_parquet(point_panel_in)\n",
    "line_panel = gpd.read_parquet(line_panel_in)\n",
    "tract_panel = gpd.read_parquet(tract_panel_in)\n",
    "comm_panel = gpd.read_parquet(comm_panel_in)\n",
    "tracts = gpd.read_parquet(tracts_in)['geoid10']\n",
    "attend = pd.read_csv(attend_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel = point_panel.pipe(date_aggs, 'date')\n",
    "line_panel = line_panel.pipe(date_aggs, 'date')\n",
    "tract_panel = tract_panel.pipe(date_aggs, 'date')\n",
    "comm_panel = comm_panel.pipe(date_aggs, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substantive!\n",
    "# There aren't enough data points within 400m or even 800m.\n",
    "# In panel.ipynb we show that UC and MP have higher ridership than other\n",
    "# places, and furthermore that the signal is stronger closer to UC and MP\n",
    "# and reverts to the mean as the buffer size grows.\n",
    "# Thus, using the largest buffer size attenuates and possibly confounds our\n",
    "# signal with irrelevant rides, but is necessary to achieve a minimal sample\n",
    "# of treated units.\n",
    "\n",
    "def label_ucmp(df):\n",
    "    is_ucmp = (df.filter(regex=r'(UNITED|MCCORMICK).*1600m$') > 0).any(axis=1)\n",
    "    df['UCMP'] = np.where(is_ucmp, 1, 0)\n",
    "    return df\n",
    "\n",
    "point_panel = point_panel.pipe(label_ucmp)\n",
    "line_panel = line_panel.pipe(label_ucmp)\n",
    "tract_panel = tract_panel.pipe(label_ucmp)\n",
    "comm_panel = comm_panel.pipe(label_ucmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_attendance(df, attend):\n",
    "    attend = attend.groupby(['date','stadium'],as_index=False)['attendance'].sum()\n",
    "    attend = attend.loc[attend.stadium != 'seatgeek'] # no transit data outside chicago\n",
    "    stadiums = {\n",
    "        'soldier': 'SOLDIER FIELD 1600m',\n",
    "        'guaranteed rate': 'GUARANTEED RATE FIELD 1600m',\n",
    "        'wrigley': 'WRIGLEY FIELD 1600m',\n",
    "        'united center': 'UNITED CENTER 1600m',\n",
    "    }\n",
    "    attend['stadium'] = attend['stadium'].map(stadiums)\n",
    "    \n",
    "    short_cols = df.filter(regex=r'00m$').columns\n",
    "    stad_cols = df.filter(regex=r'1600m$').columns\n",
    "    df = df.drop(columns=list(short_cols.difference(stad_cols))) # only need 1600m\n",
    "    df = df.melt(id_vars=list(df.columns.difference(stad_cols)),\n",
    "                 value_vars=stad_cols,\n",
    "                 var_name='stadium',\n",
    "                 value_name='near_stadium')\n",
    "    # XXX: Eventually the regression will drop non-attendance rows so might as well do it now.\n",
    "    #      This is necessary for the merge on date/stadium to work. \n",
    "    #      Because melt has already added date/stadium combos where nearby==0, and those are going to match on the merge.\n",
    "    df = df.loc[df['near_stadium']>0].drop(columns=['near_stadium'])\n",
    "    # XXX: We'll do a left-join here because I'm not ready to drop non-game-days.\n",
    "    labeled =  pd.merge(df, attend, on=['date','stadium'], how='left')\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel = point_panel.pipe(label_attendance, attend)\n",
    "line_panel = line_panel.pipe(label_attendance, attend)\n",
    "tract_panel = tract_panel.pipe(label_attendance, attend)\n",
    "comm_panel = comm_panel.pipe(label_attendance, attend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df, fills: dict):\n",
    "    return df.assign(**{col: df[col].fillna(val) for col, val in fills.items()})\n",
    "\n",
    "# Assert that null features are due to non-chicago tracts. \n",
    "# Let's impute correct values instead of dropping tracts outside of chicago (ie ubers and bike stations)\n",
    "assert all(tract_panel['UCMP'].notna() | ~tract_panel['id'].isin(tracts))\n",
    "assert all(tract_panel['airport'].notna() | ~tract_panel['id'].isin(tracts))\n",
    "assert all(point_panel[['UCMP','airport']].notna().all(axis=1) |\n",
    "         ((point_panel['transit']=='uber') & point_panel['tract'].notna()))\n",
    "\n",
    "point_panel = point_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})\n",
    "line_panel = line_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})\n",
    "tract_panel = tract_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})\n",
    "comm_panel = comm_panel.pipe(fillna, {'UCMP': 0, 'airport': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_latlong(df):\n",
    "    # Let's standardize lat/long because they are measured in millions of feet\n",
    "    # So doing so helps keep the relative scale of X vs Y in check. \n",
    "    scale = lambda x: (x - x.mean()) / x.std()\n",
    "    df['lat'] = scale(df.geometry.to_crs(LOCAL_CRS).centroid.to_crs(WORLD_CRS).y)\n",
    "    df['long'] = scale(df.geometry.to_crs(LOCAL_CRS).centroid.to_crs(WORLD_CRS).x)\n",
    "    return df\n",
    "\n",
    "point_panel = point_panel.pipe(label_latlong)\n",
    "line_panel = line_panel.pipe(label_latlong)\n",
    "tract_panel = tract_panel.pipe(label_latlong)\n",
    "comm_panel = comm_panel.pipe(label_latlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(df, col):\n",
    "    return df.assign(**{col: df[col]*1.0})\n",
    "\n",
    "point_panel = point_panel.pipe(binarize, 'DNC')\n",
    "line_panel = line_panel.pipe(binarize, 'DNC')\n",
    "tract_panel = tract_panel.pipe(binarize, 'DNC')\n",
    "comm_panel = comm_panel.pipe(binarize, 'DNC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN Check. \n",
    "assert point_panel.filter(point_panel.columns.difference(['attendance','stadium'])).notna().all(1).all()\n",
    "assert line_panel.filter(line_panel.columns.difference(['attendance','stadium'])).notna().all(1).all()\n",
    "assert tract_panel.filter(tract_panel.columns.difference(['attendance','stadium'])).notna().all(1).all()\n",
    "assert comm_panel.filter(comm_panel.columns.difference(['attendance','stadium'])).notna().all(1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Dropping nulls (they will be dropped by model anyway)\n",
    "point_panel = point_panel.loc[point_panel['attendance'].notna()]\n",
    "line_panel = line_panel.loc[line_panel['attendance'].notna()]\n",
    "tract_panel = tract_panel.loc[tract_panel['attendance'].notna()]\n",
    "comm_panel = comm_panel.loc[comm_panel['attendance'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Substantive!! \n",
    "#      Taking all weeks in June, July, August\n",
    "MODEL_PRE_WEEKS = 11\n",
    "MODEL_POST_WEEKS = 1\n",
    "\n",
    "model_start_yearweek = to_yw(from_ymd(DNC_START) - timedelta(weeks=MODEL_PRE_WEEKS))\n",
    "model_end_yearweek = to_yw(from_ymd(DNC_END) + timedelta(weeks=MODEL_POST_WEEKS))\n",
    "\n",
    "# XXX: For attendance model, choosing not to do this because it 1/2's the data\n",
    "#       and we already have reduced it to just a few locations. The extra data\n",
    "#       will not hurt our estimates of the DNC effect. It will only make more\n",
    "#       precise estimates of the non-DNC baseline. But we do need to add month fixed effects now.\n",
    "# point_panel = point_panel[point_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]\n",
    "# line_panel = line_panel[line_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]\n",
    "# tract_panel = tract_panel[tract_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]\n",
    "# comm_panel = comm_panel[comm_panel['year-week'].between(model_start_yearweek, model_end_yearweek)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_agg(df):\n",
    "    unit_aggs = {k: 'first' for k in ['UCMP','airport','lat','long','stadium',\n",
    "                                      'train_distance', 'train_contained', \n",
    "                                       'bike_distance', 'bike_contained',\n",
    "                                        'uber_distance', 'uber_contained']}\n",
    "    time_aggs = {'rides':'sum','attendance':'sum','DNC':'max', \n",
    "                 'is_weekend': 'max', 'dotw': 'max', 'monthofyear':'max'}  \n",
    "    aggs = {k:v for k,v in (unit_aggs | time_aggs).items() if k in df.columns}\n",
    "    # weekend is constant for weekly model but we just won't include it in the model spec\n",
    "    df_weekly = df.groupby(['year-week','id','transit'], as_index=False).agg(aggs)\n",
    "    df_daily = df.groupby(['date','id','transit'], as_index=False).agg(aggs)\n",
    "    return df_weekly, df_daily\n",
    "\n",
    "point_panel_weekly, point_panel_daily = model_agg(point_panel)\n",
    "line_panel_weekly, line_panel_daily = model_agg(line_panel)\n",
    "tract_panel_weekly, tract_panel_daily = model_agg(tract_panel)\n",
    "comm_panel_weekly, comm_panel_daily = model_agg(comm_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose and Justify Agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monthly: obviously stupid. attenuates treatment too much.\n",
    "\n",
    "Weekly: we have 4/7 days of the week in the DNC. and no weekend days actually.\n",
    "so we attenuate our signal by 3/7. \n",
    "\n",
    "Daily: we have more trouble modeling dotw variation. (maybe not an issue after eliminating weekends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with non-treatment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_r2(full, reduced, full_name, reduced_name):\n",
    "    better = max(full.rsquared, reduced.rsquared)\n",
    "    worse = min(full.rsquared, reduced.rsquared)\n",
    "    partial = (better - worse) / (1 - worse)  # Proportion of unexplained variance explained by better model.\n",
    "    better_name = full_name if full.rsquared > reduced.rsquared else reduced_name\n",
    "    print(\"better model = {}, R2 = {:.3f}, partial R2 = {:.3f}\".format(better_name, better, partial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better model = daily, R2 = 0.803, partial R2 = 0.168\n"
     ]
    }
   ],
   "source": [
    "# Compute the partial R2 of weekly vs daily. Only include non-treatment regressors.\n",
    "formula = \"np.log1p(rides) ~ transit + (lat + long)**2 + I(lat**2) + I(long**2)\"\n",
    "full = sm.OLS.from_formula(formula, point_panel_daily).fit()\n",
    "reduced = sm.OLS.from_formula(formula, point_panel_weekly).fit()\n",
    "partial_r2(full, reduced, \"daily\", \"weekly\")\n",
    "# The weekly model actually has a slightly higher R2, \n",
    "# meaning we're not great at explaining DOTW variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily</th>\n",
       "      <th>weekly</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.289281</td>\n",
       "      <td>5.197714</td>\n",
       "      <td>1.211791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.835855</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>1.17293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mde</th>\n",
       "      <td>0.029292</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>2.015709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_size</th>\n",
       "      <td>4.152425</td>\n",
       "      <td>5.224902</td>\n",
       "      <td>1.258277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_achieved</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_stat</th>\n",
       "      <td>397.150807</td>\n",
       "      <td>247.91559</td>\n",
       "      <td>0.624235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_detectable</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     daily     weekly     ratio\n",
       "mean              4.289281   5.197714  1.211791\n",
       "std               0.835855   0.980399   1.17293\n",
       "mde               0.029292   0.059044  2.015709\n",
       "effect_size       4.152425   5.224902  1.258277\n",
       "power_achieved         1.0        1.0       1.0\n",
       "t_stat          397.150807  247.91559  0.624235\n",
       "is_detectable         True       True       1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power analysis:\n",
    "DNC_ATTEND = 5e4\n",
    "effect_sum = 4 * 2 * DNC_ATTEND  # days in event * rides per day * attendees\n",
    "\n",
    "pd.concat([power_reg(full, np.log1p(effect_sum/len(point_panel_daily))).rename('daily'),\n",
    "           power_reg(reduced, np.log1p(effect_sum/len(point_panel_weekly))).rename('weekly')],axis=1) \\\n",
    "        .assign(ratio=lambda x: x['weekly']/x['daily'])\n",
    "# The daily model has smaller residual variance but identical power achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with treatment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better model = daily, R2 = 0.806, partial R2 = 0.172\n"
     ]
    }
   ],
   "source": [
    "# Compute the partial R2 of weekly vs daily. \n",
    "formula = \"np.log1p(rides) ~ DNC * transit + (lat + long)**2 + I(lat**2) + I(long**2)\"\n",
    "full = sm.OLS.from_formula(formula, point_panel_daily).fit()\n",
    "reduced = sm.OLS.from_formula(formula, point_panel_weekly).fit()\n",
    "partial_r2(full, reduced, \"daily\", \"weekly\")\n",
    "# The weekly model actually has a slightly higher R2, \n",
    "# meaning we're not great at explaining DOTW variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily</th>\n",
       "      <th>weekly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057656</td>\n",
       "      <td>0.123643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mde</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.007446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_size</th>\n",
       "      <td>4.152425</td>\n",
       "      <td>5.224902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_achieved</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_stat</th>\n",
       "      <td>5757.646155</td>\n",
       "      <td>1965.784433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_detectable</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      daily       weekly\n",
       "mean                    0.0          0.0\n",
       "std                0.057656     0.123643\n",
       "mde                0.002021     0.007446\n",
       "effect_size        4.152425     5.224902\n",
       "power_achieved          1.0          1.0\n",
       "t_stat          5757.646155  1965.784433\n",
       "is_detectable          True         True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([power_reg(full, np.log1p(effect_sum/len(point_panel_daily)), \"DNC\").rename('daily'),\n",
    "           power_reg(reduced, np.log1p(effect_sum/len(point_panel_weekly)), \"DNC\").rename('weekly')],axis=1) \n",
    "# The standard errors are smaller on the daily model but achieved effect size is net the same,\n",
    "# probably because we didn't change the effect delta but scaled down the nobs and effect size\n",
    "# by the same amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we'll keep the daily observations because it gives us more flexibility to \n",
    "switch to alternative treatment specifications (buffer or event study) later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_panel_daily.to_parquet(point_panel_out, index=False)\n",
    "line_panel_daily.to_parquet(line_panel_out, index=False)\n",
    "tract_panel_daily.to_parquet(tract_panel_out, index=False)\n",
    "comm_panel_daily.to_parquet(comm_panel_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
