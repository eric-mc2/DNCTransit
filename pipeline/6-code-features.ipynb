{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from data.constants import (WORLD_CRS, LOCAL_CRS, DATA_FOLDER,\n",
    "                                OHARE_CENTROID, MIDWAY_CENTROID)\n",
    "from data.geo import meter_to_foot, dms_to_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_in = os.path.join(DATA_FOLDER, \"raw\", \"train_stations.geojson\")\n",
    "bus_routes_file_in = os.path.join(DATA_FOLDER, \"raw\", \"bus_routes.geojson\")\n",
    "bus_stops_file_in = os.path.join(DATA_FOLDER, \"raw\", \"bus_stops.geojson\")\n",
    "bike_stations_file_in = os.path.join(DATA_FOLDER, \"raw\", \"bike_stations.geojson\")\n",
    "tract_file_in = os.path.join(DATA_FOLDER, \"raw\", \"tracts.geojson\")\n",
    "comm_file_in = os.path.join(DATA_FOLDER, \"raw\", \"communities.geojson\")\n",
    "poi_file_in = os.path.join(DATA_FOLDER, \"raw\", \"poi_buildings.geojson\")\n",
    "\n",
    "train_file_out = os.path.join(DATA_FOLDER, \"interim\", \"train_stations.geojson\")\n",
    "bus_routes_file_out = os.path.join(DATA_FOLDER, \"interim\", \"bus_routes.geojson\")\n",
    "bus_stops_file_out = os.path.join(DATA_FOLDER, \"interim\", \"bus_stops.geojson\")\n",
    "bike_stations_file_out = os.path.join(DATA_FOLDER, \"interim\", \"bike_stations.geojson\")\n",
    "tract_file_out = os.path.join(DATA_FOLDER, \"interim\", \"tracts.geojson\")\n",
    "comm_file_out = os.path.join(DATA_FOLDER, \"interim\", \"communities.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations = gpd.read_file(train_file_in)\n",
    "bus_routes = gpd.read_file(bus_routes_file_in)\n",
    "bus_stops = gpd.read_file(bus_stops_file_in)\n",
    "tract_points = gpd.read_file(tract_file_in)\n",
    "comm_points = gpd.read_file(comm_file_in)\n",
    "poi_buildings = gpd.read_file(poi_file_in)\n",
    "bike_stations = gpd.read_file(bike_stations_file_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTA Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can label up the train and bus stops via name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations['airport'] = (train_stations.station_name == \"O'Hare\") \\\n",
    "                            | (train_stations.station_name == \"Midway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We only check for Midway because CTA busses don't go directly into O'Hare,\n",
    "#       nor even to the adjacent Mixed Modal Transit center.\n",
    "bus_stops['airport'] = bus_stops['PUBLIC_NAM'] == \"Midway Orange Line Station\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uber Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rideshare pickups are anonymized to census area so we can't use building catchements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_xy = dms_to_decimal(*OHARE_CENTROID[1]), dms_to_decimal(*OHARE_CENTROID[0])\n",
    "oh_xy = Point(*oh_xy) # lng/lat\n",
    "oh_tract = tract_points.set_index('geoid10').geometry.contains(gpd.GeoSeries([oh_xy], crs=WORLD_CRS).to_crs(LOCAL_CRS).iloc[0])\n",
    "oh_comm = comm_points.set_index('area_num_1').geometry.contains(gpd.GeoSeries([oh_xy], crs=WORLD_CRS).to_crs(LOCAL_CRS).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdw_xy = dms_to_decimal(*MIDWAY_CENTROID[1]), dms_to_decimal(*MIDWAY_CENTROID[0])\n",
    "mdw_xy = Point(*mdw_xy) # lng/lat\n",
    "mdw_tract = tract_points.set_index('geoid10').geometry.contains(gpd.GeoSeries([mdw_xy], crs=WORLD_CRS).to_crs(LOCAL_CRS).iloc[0])\n",
    "mdw_comm = comm_points.set_index('area_num_1').geometry.contains(gpd.GeoSeries([mdw_xy], crs=WORLD_CRS).to_crs(LOCAL_CRS).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_points['airport'] = oh_tract | mdw_tract\n",
    "comm_points['airport'] = oh_comm | mdw_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to assume that no one rides a bike to the airport for out of town travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_stations['airport'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC and MP Catchements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_buffers(gdf: gpd.GeoDataFrame, geom:gpd.GeoSeries, geom_prefix:str, dists:list[int]):\n",
    "    \"\"\"\n",
    "    Computes multiple buffer distances around geom and whether each row of gdf is within buffer.\n",
    "    Params:\n",
    "        - gdf: compares each row of gdf to geom\n",
    "        - geom: the shape to compute buffers around. EXPECTS SINGLE ROW\n",
    "        - geom_prefix: name for resulting buffer comparison column\n",
    "        - dists: list of buffer radii in meters\n",
    "    \"\"\"\n",
    "    assert len(geom) == 1, \"Expects only one geom to buffer around.\"\n",
    "    building_proj = geom.geometry.to_crs(LOCAL_CRS)\n",
    "    buffers = [building_proj.buffer(meter_to_foot(d)) for d in dists]\n",
    "    df_proj = gdf.geometry.to_crs(LOCAL_CRS)\n",
    "    codes = {f\"{geom_prefix}_{d}\": df_proj.intersects(b.iloc[0]) * 1.0 for d,b in zip(dists,buffers)}\n",
    "    return gdf.assign(**codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_building = poi_buildings[poi_buildings['name'] == 'UNITED CENTER']\n",
    "mp_building = poi_buildings[poi_buildings['name'] == 'HYATT REGENCY MCCORMICK PLACE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations = train_stations.pipe(code_buffers, uc_building, \"uc\", [400,800,1600])\n",
    "bike_stations = bike_stations.pipe(code_buffers, uc_building, \"uc\", [400,800,1600])\n",
    "bus_stops = bus_stops.pipe(code_buffers, uc_building, \"uc\", [400,800,1600])\n",
    "\n",
    "train_stations = train_stations.pipe(code_buffers, mp_building, \"mp\", [400,800,1600])\n",
    "bike_stations = bike_stations.pipe(code_buffers, mp_building, \"mp\", [400,800,1600])\n",
    "bus_stops = bus_stops.pipe(code_buffers, mp_building, \"mp\", [400,800,1600])\n",
    "\n",
    "# TODO! Code tracts and community eareas??\n",
    "# Also maybe code the UC and MP community areas in the other things?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only have ridership by bus route, not bus stop, so to aggregate stops to routes,\n",
    "# we'll compute the mean number of stops within the buffer per route.\n",
    "buffer_cols = ['uc_400','uc_800','uc_1600','mp_400','mp_800','mp_1600','airport']\n",
    "bus_stops_features = bus_stops.groupby('route',as_index=False)[buffer_cols].mean()\n",
    "bus_routes = bus_routes.merge(bus_stops_features, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Need to pull in rides!\")\n",
    "        # .assign(DNC = lambda x: (x['date'] >= DNC_START_ISO) & (x['date'] <= DNC_END_ISO))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Finish refactor!\")\n",
    "def coalesce(df, left, right, coalesced):\n",
    "    predicate = df[left].isna()\n",
    "    df[coalesced] = df[left]\n",
    "    df[predicate][coalesced] = df[predicate][right]\n",
    "    return df.drop(columns=[left,right])\n",
    "\n",
    "# Half of the bike rides are already denormalized and don't need bike-stations\n",
    "# So we do a left-join and coalesce to get the missing geometries\n",
    "bike_rides = bike_rides.merge(bike_stations.assign(station_id=bike_stations.station_id.astype(str)),\n",
    "                                on=['station_id','vintage'], how='left')\n",
    "bike_rides = bike_rides.pipe(coalesce, 'geometry_x','geometry_y','geometry')\n",
    "# Bikes don't have the daytype column so we'll impute it\n",
    "daytypes = pd.concat([train_rides[['date','daytype']],bus_rides[['date','daytype']]],ignore_index=True)\n",
    "daytypes = daytypes.groupby('date')['daytype'].first()\n",
    "bike_rides['daytype'] = bike_rides['date'].map(daytypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations.to_file(train_file_out, index=False)\n",
    "bus_routes.to_file(bus_routes_file_out, index=False)\n",
    "bus_stops.to_file(bus_stops_file_out, index=False)\n",
    "tract_points.to_file(tract_file_out, index=False)\n",
    "comm_points.to_file(comm_file_out, index=False)\n",
    "bike_stations.to_file(bike_stations_file_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
