{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.constants import (DATA_FOLDER, DNC_START_ISO, DNC_END_ISO,\n",
    "                            L_RIDERSHIP_TABLE, BUS_RIDERSHIP_TABLE)\n",
    "from data.cta import CTAClient\n",
    "from data.divvy import DivvyClient\n",
    "from data.uber import UberClient\n",
    "from data.datemath import iso_to_ymd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_in = os.path.join(DATA_FOLDER, \"interim\", \"train_stations.geojson\")\n",
    "bus_routes_file_in = os.path.join(DATA_FOLDER, \"interim\", \"bus_routes.geojson\")\n",
    "bus_stops_file_in = os.path.join(DATA_FOLDER, \"interim\", \"bus_stops.geojson\")\n",
    "bike_stations_file_in = os.path.join(DATA_FOLDER, \"interim\", \"bike_stations.geojson\")\n",
    "tract_file_in = os.path.join(DATA_FOLDER, \"interim\", \"tracts.geojson\")\n",
    "comm_file_in = os.path.join(DATA_FOLDER, \"interim\", \"communities.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rides_out = os.path.join(DATA_FOLDER, \"interim\", \"train_rides.csv\")\n",
    "bus_rides_out = os.path.join(DATA_FOLDER, \"raw\", \"bus_rides.csv\")\n",
    "bike_rides_out = os.path.join(DATA_FOLDER, \"raw\", \"bike_rides.csv\")\n",
    "uber_rides_out = os.path.join(DATA_FOLDER, \"interim\", \"uber_rides.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n",
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "cta_client = CTAClient(60)\n",
    "divvy_client = DivvyClient()\n",
    "uber_client = UberClient(600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations = gpd.read_file(train_file_in)\n",
    "bus_routes = gpd.read_file(bus_routes_file_in)\n",
    "bus_stops = gpd.read_file(bus_stops_file_in)\n",
    "tract_points = gpd.read_file(tract_file_in)\n",
    "comm_points = gpd.read_file(comm_file_in)\n",
    "bike_stations = gpd.read_file(bike_stations_file_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these tables are rather large so we need to make good choices about\n",
    "what to pull in. We should abstract any logic that we might need to re-do\n",
    "if we want to pull in additional dates, and cache anything that takes a while to load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking ahead, we use models with -1 week, -1 month, and -1 YTD, at daily granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start_iso = dt(2024, 1, 1).isoformat()\n",
    "data_end_iso = DNC_END_ISO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rides = cta_client.soda_get_all(L_RIDERSHIP_TABLE, \n",
    "                            select=\"station_id,date,daytype,rides\",\n",
    "                            where=f\"date between '{data_start_iso}' and '{data_end_iso}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus Rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_rides = cta_client.soda_get_all(BUS_RIDERSHIP_TABLE, \n",
    "                            select=\"route,date,daytype,rides\",\n",
    "                            where=f\"date between '{data_start_iso}' and '{data_end_iso}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The divvy ridership are at the ride granularity, so we need to aggregate to station-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ridership(trips: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get counts by station and date.\n",
    "    \"\"\"\n",
    "    trips['start_date'] = trips['start_time'].dt.date\n",
    "    trips['end_date'] = trips['end_time'].dt.date\n",
    "    id_cols = ['station_id','date','vintage'] \n",
    "    id_cols += ['geometry'] if any('geometry' in x for x in trips.columns) else []\n",
    "    start_rides = trips.rename(columns=lambda x: x.replace('start_','')) \\\n",
    "                    .groupby(id_cols, as_index=False).size() \\\n",
    "                    .rename(columns={'size': 'start_rides'})\n",
    "    end_rides = trips.rename(columns=lambda x: x.replace('end_','')) \\\n",
    "                    .groupby(id_cols, as_index=False).size() \\\n",
    "                    .rename(columns={'size': 'end_rides'})\n",
    "    rides = start_rides.merge(end_rides, how='outer')\n",
    "    rides['rides'] = rides['start_rides'].fillna(0) + rides['end_rides'].fillna(0)\n",
    "    return rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: populating bucket paths.\n",
      "DEBUG: reading  s3://divvy-tripdata/202401-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:23, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202402-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:30, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202403-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:41, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202404-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:54, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202405-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:13, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202406-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:52, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202407-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [02:17, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202408-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [03:08, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202409-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [03:27, 25.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m bike_rides \u001b[38;5;241m=\u001b[39m divvy_client\u001b[38;5;241m.\u001b[39ms3_bike_trips(dt\u001b[38;5;241m.\u001b[39mfromisoformat(data_start_iso)\u001b[38;5;241m.\u001b[39myear, \n\u001b[1;32m      2\u001b[0m                                         dt\u001b[38;5;241m.\u001b[39mfromisoformat(data_end_iso)\u001b[38;5;241m.\u001b[39myear)\n\u001b[1;32m      3\u001b[0m bike_rides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(agg_ridership, bike_rides)\n\u001b[0;32m----> 4\u001b[0m bike_rides \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbike_rides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# bike_rides = bike_rides.query(f\"(date >= '{data_start_iso}') & (date <= '{data_end_iso}')\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/DNCTransit/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Dev/DNCTransit/src/data/divvy.py:127\u001b[0m, in \u001b[0;36mDivvyClient.s3_bike_trips\u001b[0;34m(self, min_year, max_year)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms3\u001b[38;5;241m.\u001b[39mopen(zip_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m s3f, ZipFile(s3f) \u001b[38;5;28;01mas\u001b[39;00m zf, zf\u001b[38;5;241m.\u001b[39mopen(trip_path) \u001b[38;5;28;01mas\u001b[39;00m tripf:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: reading \u001b[39m\u001b[38;5;124m\"\u001b[39m, zip_path)\n\u001b[0;32m--> 127\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_trip_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtripf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39massign(vintage\u001b[38;5;241m=\u001b[39mbasename(zip_path))\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m df\n",
      "File \u001b[0;32m~/Dev/DNCTransit/src/data/divvy.py:57\u001b[0m, in \u001b[0;36mDivvyClient._read_trip_file\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m     55\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fp)\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trip_schema)\n\u001b[1;32m     56\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoerce\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_lng\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     59\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_geometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_lng\u001b[39m\u001b[38;5;124m'\u001b[39m],df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_lat\u001b[39m\u001b[38;5;124m'\u001b[39m],crs\u001b[38;5;241m=\u001b[39mWORLD_CRS)\n",
      "File \u001b[0;32m~/Dev/DNCTransit/.venv/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/Dev/DNCTransit/.venv/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/DNCTransit/.venv/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bike_rides = divvy_client.s3_bike_trips(dt.fromisoformat(data_start_iso).year, \n",
    "                                        dt.fromisoformat(data_end_iso).year)\n",
    "bike_rides = map(agg_ridership, bike_rides)\n",
    "bike_rides = pd.concat(list(tqdm(bike_rides)), ignore_index=True)\n",
    "# bike_rides = bike_rides.query(f\"(date >= '{data_start_iso}') & (date <= '{data_end_iso}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uber Rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_pickups = uber_client.soda_get_uber(iso_to_ymd(data_start_iso), iso_to_ymd(data_end_iso), True)\n",
    "uber_dropoffs = uber_client.soda_get_uber(iso_to_ymd(data_start_iso), iso_to_ymd(data_end_iso), False)\n",
    "uber_rides = pd.concat([uber_pickups, uber_dropoffs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rides.to_csv(train_rides_out, ignore_index=True)\n",
    "bus_rides.to_csv(bus_rides_out, ignore_index=True)\n",
    "bike_rides.to_csv(bike_rides_out, ignore_index=True)\n",
    "uber_rides.to_csv(uber_rides_out, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
