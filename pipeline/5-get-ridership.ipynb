{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.constants import (DATA_FOLDER, DNC_START_ISO, DNC_END_ISO,\n",
    "                            L_RIDERSHIP_TABLE, BUS_RIDERSHIP_TABLE)\n",
    "from data.cta import CTAClient\n",
    "from data.divvy import DivvyClient\n",
    "from data.uber import UberClient\n",
    "from data.datemath import iso_to_ymd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_in = os.path.join(DATA_FOLDER, \"interim\", \"train_stations.geojson\")\n",
    "bus_routes_file_in = os.path.join(DATA_FOLDER, \"interim\", \"bus_routes.geojson\")\n",
    "bus_stops_file_in = os.path.join(DATA_FOLDER, \"interim\", \"bus_stops.geojson\")\n",
    "bike_stations_file_in = os.path.join(DATA_FOLDER, \"interim\", \"bike_stations.geojson\")\n",
    "tract_file_in = os.path.join(DATA_FOLDER, \"interim\", \"tracts.geojson\")\n",
    "comm_file_in = os.path.join(DATA_FOLDER, \"interim\", \"communities.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rides_out = os.path.join(DATA_FOLDER, \"interim\", \"train_rides.csv\")\n",
    "bus_rides_out = os.path.join(DATA_FOLDER, \"raw\", \"bus_rides.csv\")\n",
    "bike_rides_out = os.path.join(DATA_FOLDER, \"raw\", \"bike_rides.csv\")\n",
    "uber_rides_out = os.path.join(DATA_FOLDER, \"interim\", \"uber_rides.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n",
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "cta_client = CTAClient(60)\n",
    "divvy_client = DivvyClient()\n",
    "uber_client = UberClient(600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stations = gpd.read_file(train_file_in)\n",
    "bus_routes = gpd.read_file(bus_routes_file_in)\n",
    "bus_stops = gpd.read_file(bus_stops_file_in)\n",
    "tract_points = gpd.read_file(tract_file_in)\n",
    "comm_points = gpd.read_file(comm_file_in)\n",
    "bike_stations = gpd.read_file(bike_stations_file_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these tables are rather large so we need to make good choices about\n",
    "what to pull in. We should abstract any logic that we might need to re-do\n",
    "if we want to pull in additional dates, and cache anything that takes a while to load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking ahead, we use models with -1 week, -1 month, and -1 YTD, at daily granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start_iso = dt(2024, 1, 1).isoformat()\n",
    "data_end_iso = DNC_END_ISO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rides = cta_client.soda_get_all(L_RIDERSHIP_TABLE, \n",
    "                            select=\"station_id,date,daytype,rides\",\n",
    "                            where=f\"date between '{data_start_iso}' and '{data_end_iso}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus Rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_rides = cta_client.soda_get_all(BUS_RIDERSHIP_TABLE, \n",
    "                            select=\"route,date,daytype,rides\",\n",
    "                            where=f\"date between '{data_start_iso}' and '{data_end_iso}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The divvy ridership are at the ride granularity, so we need to aggregate to station-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ridership(trips: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get counts by station and date.\n",
    "    \"\"\"\n",
    "    trips['start_date'] = trips['start_time'].dt.date\n",
    "    trips['end_date'] = trips['end_time'].dt.date\n",
    "    id_cols = ['station_id','date','vintage'] \n",
    "    id_cols += ['geometry'] if any('geometry' in x for x in trips.columns) else []\n",
    "    start_rides = trips.rename(columns=lambda x: x.replace('start_','')) \\\n",
    "                    .groupby(id_cols, as_index=False).size() \\\n",
    "                    .rename(columns={'size': 'start_rides'})\n",
    "    end_rides = trips.rename(columns=lambda x: x.replace('end_','')) \\\n",
    "                    .groupby(id_cols, as_index=False).size() \\\n",
    "                    .rename(columns={'size': 'end_rides'})\n",
    "    rides = start_rides.merge(end_rides, how='outer')\n",
    "    rides['rides'] = rides['start_rides'].fillna(0) + rides['end_rides'].fillna(0)\n",
    "    return rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: populating bucket paths.\n",
      "DEBUG: reading  s3://divvy-tripdata/202401-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:33, 33.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202402-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:38, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202403-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:46, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202404-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:59, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202405-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:09, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202406-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:26, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202407-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:47, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202408-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:59, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: reading  s3://divvy-tripdata/202409-divvy-tripdata.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:15, 15.10s/it]\n"
     ]
    }
   ],
   "source": [
    "bike_rides = divvy_client.s3_bike_trips(dt.fromisoformat(data_start_iso).year, \n",
    "                                        dt.fromisoformat(data_end_iso).year)\n",
    "bike_rides = map(agg_ridership, bike_rides)\n",
    "bike_rides = pd.concat(list(tqdm(bike_rides)), ignore_index=True)\n",
    "bike_rides = bike_rides.loc[(bike_rides['date'] >= dt.fromisoformat(data_start_iso).date()) \\\n",
    "                            & (bike_rides['date'] <= dt.fromisoformat(data_end_iso).date())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO! \n",
    "# We should buffer-agg these bike stations!\n",
    "# Each station is actually a single dock, not the rack! (I think ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uber Rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_pickups = uber_client.soda_get_uber(select=\"\"\"\n",
    "                                         date_trunc_ymd(trip_start_timestamp) as start_date, \n",
    "                                         pickup_census_tract as start_tract,\n",
    "                                         count(trip_id) as rides\n",
    "                                         \"\"\",\n",
    "                                         where_start=iso_to_ymd(data_start_iso), \n",
    "                                         where_end=iso_to_ymd(data_end_iso), \n",
    "                                         group=\"start_date, start_tract\",\n",
    "                                         pickup=True)\n",
    "uber_dropoffs = uber_client.soda_get_uber(select=\"\"\"\n",
    "                                         date_trunc_ymd(trip_end_timestamp) as end_date, \n",
    "                                         dropoff_census_tract as end_tract,\n",
    "                                         count(trip_id) as rides\n",
    "                                         \"\"\",\n",
    "                                         where_start=iso_to_ymd(data_start_iso), \n",
    "                                         where_end=iso_to_ymd(data_end_iso), \n",
    "                                         group=\"end_date, end_tract\",\n",
    "                                         pickup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_pickups = uber_pickups.rename(columns={'start_date':'date', 'start_tract':'tract', 'rides':'start_rides'})\n",
    "uber_dropoffs = uber_dropoffs.rename(columns={'end_date':'date', 'end_tract':'tract', 'rides':'end_rides'})\n",
    "uber_rides = uber_pickups.merge(uber_dropoffs, how='outer')\n",
    "uber_rides['rides'] = uber_rides['start_rides'].fillna(0) + uber_rides['end_rides'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rides.to_csv(train_rides_out, index=False)\n",
    "bus_rides.to_csv(bus_rides_out, index=False)\n",
    "bike_rides.to_csv(bike_rides_out, index=False)\n",
    "uber_rides.to_csv(uber_rides_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
