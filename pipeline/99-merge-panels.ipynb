{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from src.data.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_out = os.path.join(DATA_FOLDER, \"interim\", \"train_stations.geojson\")\n",
    "bus_routes_file_out = os.path.join(DATA_FOLDER, \"interim\", \"bus_routes.geojson\")\n",
    "bus_stops_file_out = os.path.join(DATA_FOLDER, \"interim\", \"bus_stops.geojson\")\n",
    "bike_stations_file_out = os.path.join(DATA_FOLDER, \"interim\", \"bike_stations.geojson\")\n",
    "tract_file_out = os.path.join(DATA_FOLDER, \"interim\", \"tracts.geojson\")\n",
    "comm_file_out = os.path.join(DATA_FOLDER, \"interim\", \"communities.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_panels(bus=None, train=None, bike=None):\n",
    "    if bus is not None:\n",
    "        bus = bus.rename(columns={'route':'id'}).assign(transit='bus', tid=\"bus_\"+bus['route'].astype(str))\n",
    "    if train is not None:\n",
    "        train = train.rename(columns={'map_id':'id'}).assign(transit='train', tid=\"train_\"+train['map_id'].astype(str))\n",
    "    if bike is not None:\n",
    "        bike = bike.rename(columns={'station_id':'id'}).assign(transit='bike', tid=\"bike_\"+bike['station_id'].astype(str))\n",
    "    panel = pd.concat(filter(lambda x: x is not None and not x.empty, [bus,train,bike]), ignore_index=True, join='inner')\n",
    "    panel['lat'] = gpd.GeoSeries(panel.geometry).to_crs(LOCAL_CRS).centroid.y\n",
    "    panel['long'] = gpd.GeoSeries(panel.geometry).to_crs(LOCAL_CRS).centroid.x\n",
    "    panel = panel.drop(columns=['geometry'])\n",
    "    return panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coalesce(df, left, right, coalesced):\n",
    "    predicate = df[left].isna()\n",
    "    df[coalesced] = df[left]\n",
    "    df[predicate][coalesced] = df[predicate][right]\n",
    "    return df.drop(columns=[left,right])\n",
    "\n",
    "def get_rides_panel(ctl_start, ctl_end, trt_start, trt_end):\n",
    "    soql_where_date = f\"\"\"(('{trt_start}' <= date) AND (date <= '{trt_end}'))\n",
    "                OR (('{ctl_start}' <= date) AND (date <= '{ctl_end}'))\"\"\"\n",
    "    def _pd_where_date(x):\n",
    "        dts = pd.to_datetime(pd.Series([ctl_start, ctl_end, trt_start, trt_end]))\n",
    "        return ((dts[0] <= x['date']) & (x['date'] <= dts[1])) | \\\n",
    "                ((dts[2] <= x['date']) & (x['date'] <= dts[3]))\n",
    "    \n",
    "    train_rides = soda_get_all(L_RIDERSHIP_TABLE, \n",
    "                            select=\"station_id,date,daytype,rides\",\n",
    "                            where=soql_where_date) \\\n",
    "                .merge(train_stations, left_on='station_id', right_on='map_id')\n",
    "\n",
    "    bus_rides = soda_get_all(BUS_RIDERSHIP_TABLE, \n",
    "                            select=\"route,date,daytype,rides\",\n",
    "                            where=soql_where_date) \\\n",
    "                .merge(bus_routes, on='route')\n",
    "\n",
    "    bike_rides = s3_bike_trips(datetime.fromisoformat(ctl_start).year, \n",
    "                            datetime.fromisoformat(trt_end).year) \\\n",
    "                .pipe(agg_bike_trips) \\\n",
    "                .loc[_pd_where_date]\n",
    "    # Half of the bike rides are already denormalized and don't need bike-stations\n",
    "    # So we do a left-join and coalesce to get the missing geometries\n",
    "    bike_rides = bike_rides.merge(bike_stations.assign(station_id=bike_stations.station_id.astype(str)),\n",
    "                                   on=['station_id','vintage'], how='left')\n",
    "    bike_rides = bike_rides.pipe(coalesce, 'geometry_x','geometry_y','geometry')\n",
    "    # Bikes don't have the daytype column so we'll impute it\n",
    "    daytypes = pd.concat([train_rides[['date','daytype']],bus_rides[['date','daytype']]],ignore_index=True)\n",
    "    daytypes = daytypes.groupby('date')['daytype'].first()\n",
    "    bike_rides['daytype'] = bike_rides['date'].map(daytypes)\n",
    "    \n",
    "    rides = combine_panels(bus_rides, train_rides, bike_rides)\n",
    "    rides['DNC'] = (trt_start <= rides['date']) & (rides['date'] <= trt_end)\n",
    "    return rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def _soql_where_date(ctl_start, ctl_end, trt_start, trt_end):\n",
    "    return  f\"\"\"(('{trt_start}' <= date) AND (date <= '{trt_end}'))\n",
    "                OR (('{ctl_start}' <= date) AND (date <= '{ctl_end}'))\"\"\"\n",
    "\n",
    "\n",
    "def _pd_where_date(x: pd.DataFrame, ctl_start, ctl_end, trt_start, trt_end):\n",
    "    dts = pd.to_datetime(pd.Series([ctl_start, ctl_end, trt_start, trt_end]))\n",
    "    return ((dts[0] <= x['date']) & (x['date'] <= dts[1])) | \\\n",
    "            ((dts[2] <= x['date']) & (x['date'] <= dts[3]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
